---
title: "Interactive Linear Regression Lab"
format: live-html
jupyter: python3
thebe:
  use_thebe: true
  binderOptions:
    repo: sandeepnarasimhan/Neural-Notes
    ref: main
    binderUrl: https://mybinder.org
---
[![Tweet](https://img.shields.io/badge/Tweet-Share_on_Twitter-1DA1F2?logo=twitter)](https://twitter.com/intent/tweet?text=Check%20out%20this%20post!&url=https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)
[![LinkedIn](https://img.shields.io/badge/Share-LinkedIn-blue?logo=linkedin)](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)
[![Email](https://img.shields.io/badge/Email-Share_via_Email-red?logo=gmail)](mailto:?subject=Interesting%20Post&body=Check%20out%20this%20blog%20post%3A%20https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)
[![WhatsApp](https://img.shields.io/badge/WhatsApp-Share-25D366?logo=whatsapp&logoColor=white)](https://api.whatsapp.com/send?text=Check%20out%20this%20blog%20post%3A%20https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)
[![Reddit](https://img.shields.io/badge/Reddit-Share-orange?logo=reddit)](https://www.reddit.com/submit?url=https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html&title=Virtual%20Environments)


::: {.callout-warning icon="üõ†Ô∏è" .bg-yellow-100 .border-yellow-500 .text-yellow-800}
**üöß Work in Progress!**  
**Hey! I‚Äôm still working on this post. If you‚Äôre interested, keep an eye out for updates here ‚Äî exciting stuff coming soon!!**
:::

This interactive lab demonstrates a simple linear regression using `scikit-learn`.

You can **click on the code blocks and run them interactively** in your browser!

---

## What is Linear Regression?

Linear regression tries to model the relationship between a dependent variable \( y \) and one or more independent variables \( x \).  
The simplest form (simple linear regression) fits a line:

\[
y = \beta_0 + \beta_1 x + \epsilon
\]

where:
- \( \beta_0 \) is the intercept
- \( \beta_1 \) is the slope (coefficient)
- \( \epsilon \) is the error term

---

## Import libraries and generate a synthetic data
```{pyodide}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Generate synthetic data
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)  # y = 4 + 3x + noise

plt.scatter(X, y, alpha=0.6)
plt.xlabel('X')
plt.ylabel('y')
plt.title('Generated Data')
plt.show()
```

## Fit Linear Regression Model
```{pyodide}
model = LinearRegression()
model.fit(X, y)

print(f"Intercept (Œ≤‚ÇÄ): {model.intercept_[0]:.2f}")
print(f"Coefficient (Œ≤‚ÇÅ): {model.coef_[0][0]:.2f}")
```

## Visualize the Regression Line
```{pyodide}
plt.scatter(X, y, alpha=0.6, label='Data')
plt.plot(X, model.predict(X), color='red', label='Regression Line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression Fit')
plt.legend()
plt.show()
```

## Make Predictions with Your Own Input
### Change the value of x_new below and rerun to predict a new output.
```{pyodide}
# You can edit this value to predict for different inputs!
x_new = 1.5  # <-- Try changing this!

x_new_array = np.array([[x_new]])
y_pred = model.predict(x_new_array)

print(f"Predicted y for x={x_new}: {y_pred[0][0]:.2f}")
```