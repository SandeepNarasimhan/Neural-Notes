{
  "hash": "f3dd2dda241fad723387e68e3c5fa39c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Interactive Linear Regression Lab\nformat: live-html\nthebe:\n  use_thebe: true\n  binderOptions:\n    repo: sandeepnarasimhan/Neural-Notes\n    ref: main\n    binderUrl: https://mybinder.org\n---\n\n[![Tweet](https://img.shields.io/badge/Tweet-Share_on_Twitter-1DA1F2?logo=twitter)](https://twitter.com/intent/tweet?text=Check%20out%20this%20post!&url=https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)\n[![LinkedIn](https://img.shields.io/badge/Share-LinkedIn-blue?logo=linkedin)](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)\n[![Email](https://img.shields.io/badge/Email-Share_via_Email-red?logo=gmail)](mailto:?subject=Interesting%20Post&body=Check%20out%20this%20blog%20post%3A%20https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)\n[![WhatsApp](https://img.shields.io/badge/WhatsApp-Share-25D366?logo=whatsapp&logoColor=white)](https://api.whatsapp.com/send?text=Check%20out%20this%20blog%20post%3A%20https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html)\n[![Reddit](https://img.shields.io/badge/Reddit-Share-orange?logo=reddit)](https://www.reddit.com/submit?url=https%3A%2F%2Fsandeepnarasimhan.github.io%2FNeural-Notes%2Fposts%2FVenvs.html&title=Virtual%20Environments)\n\n\n::: {.callout-warning icon=\"üõ†Ô∏è\" .bg-yellow-100 .border-yellow-500 .text-yellow-800}\n**üöß Work in Progress!**  \n**Hey! I‚Äôm still working on this post. If you‚Äôre interested, keep an eye out for updates here ‚Äî exciting stuff coming soon!!**\n:::\n\nThis interactive lab demonstrates a simple linear regression using `scikit-learn`.\n\nYou can **click on the code blocks and run them interactively** in your browser!\n\n---\n\n## What is Linear Regression?\n\nLinear regression tries to model the relationship between a dependent variable \\( y \\) and one or more independent variables \\( x \\).  \nThe simplest form (simple linear regression) fits a line:\n\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\]\n\nwhere:\n- \\( \\beta_0 \\) is the intercept\n- \\( \\beta_1 \\) is the slope (coefficient)\n- \\( \\epsilon \\) is the error term\n\n---\n\n## Import libraries and generate a synthetic data\n```{pyodide}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic data\nnp.random.seed(42)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)  # y = 4 + 3x + noise\n\nplt.scatter(X, y, alpha=0.6)\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Generated Data')\nplt.show()\n```\n\n## Fit Linear Regression Model\n```{pyodide}\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint(f\"Intercept (Œ≤‚ÇÄ): {model.intercept_[0]:.2f}\")\nprint(f\"Coefficient (Œ≤‚ÇÅ): {model.coef_[0][0]:.2f}\")\n```\n\n## Visualize the Regression Line\n```{pyodide}\nplt.scatter(X, y, alpha=0.6, label='Data')\nplt.plot(X, model.predict(X), color='red', label='Regression Line')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Linear Regression Fit')\nplt.legend()\nplt.show()\n```\n\n## Make Predictions with Your Own Input\n### Change the value of x_new below and rerun to predict a new output.\n```{pyodide}\n# You can edit this value to predict for different inputs!\nx_new = 1.5  # <-- Try changing this!\n\nx_new_array = np.array([[x_new]])\ny_pred = model.predict(x_new_array)\n\nprint(f\"Predicted y for x={x_new}: {y_pred[0][0]:.2f}\")\n```\n\n",
    "supporting": [
      "regression_lab_files"
    ],
    "filters": [],
    "includes": {}
  }
}